# FOV ë‚´ ë‹¤ë¥¸ ë¡œë´‡ Trajectoryë¥¼ í™œìš©í•œ ê°•í™”í•™ìŠµ êµ¬í˜„

ì´ ë¬¸ì„œëŠ” ë‹¤ì¤‘ ë¡œë´‡ íƒì‚¬ ì‹œë®¬ë ˆì´ì…˜ì—ì„œ FOV(Field of View) ë‚´ì— ê°ì§€ëœ ë‹¤ë¥¸ ë¡œë´‡ì˜ trajectoryë¥¼ ê°•í™”í•™ìŠµì— í™œìš©í•˜ê¸° ìœ„í•œ êµ¬í˜„ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

## ðŸ“‹ êµ¬í˜„ ê°œìš”

**ëª©í‘œ**: ë¡œë´‡ì´ ìžì‹ ì˜ FOV ë‚´ì— ë‹¤ë¥¸ ë¡œë´‡ì„ ê°ì§€í•˜ë©´, í•´ë‹¹ ë¡œë´‡ë“¤ì˜ ìµœê·¼ trajectoryë¥¼ ì¶”ì¶œí•˜ì—¬ ê°•í™”í•™ìŠµ ì‹œ observationì— í¬í•¨

**í•µì‹¬ ê¸°ìˆ **:
- **Temporal Transformer**: ì‹œê³„ì—´ trajectory ë°ì´í„°ë¥¼ ì²˜ë¦¬
- **Multi-Head Attention**: ì—¬ëŸ¬ ë¡œë´‡ì˜ trajectoryë¥¼ aggregation
- **Positional Encoding**: ì‹œê°„ ì •ë³´ ì¸ì½”ë”©

---

## ðŸ”§ ì£¼ìš” ë³€ê²½ ì‚¬í•­

### 1. **parameter.py** - Trajectory íŒŒë¼ë¯¸í„° ì¶”ê°€

```python
# Trajectory tracking parameters
TRAJECTORY_HISTORY_LENGTH = 10  # Number of recent steps to track
TRAJECTORY_FEATURE_DIM = 4      # (dx, dy, heading, velocity)
TRAJECTORY_EMBEDDING_DIM = 64   # Trajectory encoder output dimension
MAX_DETECTED_AGENTS = N_AGENTS - 1  # Maximum number of detectable agents in FOV
```

**ìœ„ì¹˜**: Line 80-84

---

### 2. **utils/multi_agent_worker.py** - Trajectory Buffer êµ¬í˜„

#### ë³€ê²½ ì‚¬í•­:
1. **Import ì¶”ê°€**:
   ```python
   from collections import deque
   ```

2. **Trajectory Buffer ì´ˆê¸°í™”** (`__init__` ë©”ì„œë“œ):
   ```python
   # Initialize trajectory buffer for each agent
   self.trajectory_buffer = {}
   for i in range(self.n_agents):
       self.trajectory_buffer[i] = deque(maxlen=TRAJECTORY_HISTORY_LENGTH)
       # Initialize with starting positions (x, y, heading, velocity=0)
       start_location = self.env.robot_locations[i]
       self.trajectory_buffer[i].append((
           start_location[0],
           start_location[1],
           self.env.angles[i],
           0.0
       ))
   ```

3. **Trajectory ì—…ë°ì´íŠ¸** (`run_episode` ë©”ì„œë“œ, reward ê³„ì‚° ë¶€ë¶„):
   ```python
   # Update trajectory buffer
   prev_trajectory = self.trajectory_buffer[robot.id][-1] if len(self.trajectory_buffer[robot.id]) > 0 else None
   if prev_trajectory is not None:
       prev_x, prev_y = prev_trajectory[0], prev_trajectory[1]
       velocity = np.linalg.norm(next_location - np.array([prev_x, prev_y])) / NUM_SIM_STEPS
   else:
       velocity = 0.0

   self.trajectory_buffer[robot.id].append((
       next_location[0],
       next_location[1],
       robot.heading,
       velocity
   ))
   ```

4. **Observation ìƒì„± ì‹œ trajectory_buffer ì „ë‹¬**:
   ```python
   # ê¸°ì¡´ ì½”ë“œ (2ê³³):
   observation = robot.get_observation()

   # ë³€ê²½ í›„:
   observation = robot.get_observation(
       robot_locations=self.env.robot_locations,
       trajectory_buffer=self.trajectory_buffer
   )
   ```

**ìœ„ì¹˜**: Line 27, 64-75, 168-181, 91-94, 241-244

---

### 3. **utils/agent.py** - FOV ê°ì§€ ë° Trajectory ì¶”ì¶œ

#### ì¶”ê°€ëœ ë©”ì„œë“œ:

1. **`get_robots_in_fov(self, robot_locations)`**:
   - FOV ë‚´ì— ìžˆëŠ” ë‹¤ë¥¸ ë¡œë´‡ ê°ì§€
   - ê±°ë¦¬ ì²´í¬ (sensor_range ì´ë‚´)
   - ê°ë„ ì²´í¬ (FOV ë²”ìœ„ ë‚´)
   - ë°˜í™˜: ê°ì§€ëœ ë¡œë´‡ ID ë¦¬ìŠ¤íŠ¸

2. **`_get_detected_trajectories(self, robot_locations, trajectory_buffer)`**:
   - ê°ì§€ëœ ë¡œë´‡ë“¤ì˜ trajectory ì¶”ì¶œ
   - ìƒëŒ€ ì¢Œí‘œë¡œ ë³€í™˜ ë° ì •ê·œí™”
   - Padding ì²˜ë¦¬ (MAX_DETECTED_AGENTSê¹Œì§€)
   - ë°˜í™˜: (detected_trajectories, trajectory_mask) í…ì„œ

3. **`get_observation()` ë©”ì„œë“œ ìˆ˜ì •**:
   ```python
   # ê¸°ì¡´ signature:
   def get_observation(self, pad=True):

   # ë³€ê²½ í›„:
   def get_observation(self, pad=True, robot_locations=None, trajectory_buffer=None):

   # ë°˜í™˜ê°’ ë³€ê²½ (9ê°œ â†’ 11ê°œ):
   return [node_inputs, node_padding_mask, edge_mask, current_index, current_edge, edge_padding_mask,
           all_node_frontier_distribution, node_heading_visited, node_neighbor_best_headings,
           detected_trajectories, trajectory_mask]  # 2ê°œ ì¶”ê°€
   ```

4. **`select_next_waypoint()` ë©”ì„œë“œ ìˆ˜ì •**:
   ```python
   # ê¸°ì¡´:
   _, _, _, _, current_edge, _, _, _, _ = observation
   logp = self.policy_net(*observation)

   # ë³€ê²½ í›„:
   _, _, _, _, current_edge, _, _, _, _, _, _ = observation
   logp = self.policy_net(*observation[:9], detected_trajectories=observation[9], trajectory_mask=observation[10])
   ```

5. **`save_observation()` ë©”ì„œë“œ ìˆ˜ì •**:
   ```python
   # ê¸°ì¡´:
   node_inputs, ..., neighbor_best_headings = observation

   # ë³€ê²½ í›„:
   node_inputs, ..., neighbor_best_headings, detected_trajectories, trajectory_mask = observation
   # Note: detected_trajectoriesì™€ trajectory_maskëŠ” episode_bufferì— ì €ìž¥í•˜ì§€ ì•ŠìŒ
   ```

**ìœ„ì¹˜**: Line 182, 245-255, 257-260, 384-486, 510-521, 544

---

### 4. **utils/model.py** - Trajectory Encoder ë° Network í†µí•©

#### ìƒˆë¡œ ì¶”ê°€ëœ í´ëž˜ìŠ¤:

1. **`PositionalEncoding`**:
   - ì‹œê°„ ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ëŠ” Positional Encoding
   - Sinusoidal ë°©ì‹ ì‚¬ìš©

2. **`TrajectoryEncoder`**:
   ```python
   class TrajectoryEncoder(nn.Module):
       def __init__(self, feature_dim, trajectory_embedding_dim, seq_len, n_head=4, n_layer=2):
           # Feature projection
           self.feature_projection = nn.Linear(feature_dim, trajectory_embedding_dim)

           # Positional encoding
           self.positional_encoding = PositionalEncoding(trajectory_embedding_dim, max_len=seq_len)

           # Temporal transformer encoder
           self.temporal_encoder = Encoder(embedding_dim=trajectory_embedding_dim, n_head=n_head, n_layer=n_layer)

           # Agent aggregation
           self.agent_attention = MultiHeadAttention(trajectory_embedding_dim, n_heads=n_head)

           # Output projection
           self.output_layer = nn.Sequential(...)
   ```

   **ì²˜ë¦¬ íë¦„**:
   1. Input: `[batch, max_detected_agents, seq_len, feature_dim]`
   2. Feature Projection â†’ Positional Encoding
   3. Temporal Transformer (ê° agentì˜ trajectory ë…ë¦½ì ìœ¼ë¡œ ì¸ì½”ë”©)
   4. Agent Aggregation (Multi-Head Attention)
   5. Output: `[batch, trajectory_embedding_dim]`

#### PolicyNet ìˆ˜ì •:

```python
class PolicyNet(nn.Module):
    def __init__(self, node_dim, embedding_dim, num_angles_bin, use_trajectory=True):
        # Trajectory encoder ì¶”ê°€
        if use_trajectory:
            self.trajectory_encoder = TrajectoryEncoder(...)
            self.trajectory_fusion = nn.Linear(embedding_dim + TRAJECTORY_EMBEDDING_DIM, embedding_dim)

    def decode_state(self, ..., trajectory_embedding=None):
        # Trajectory embeddingê³¼ current stateë¥¼ fusion
        if self.use_trajectory and trajectory_embedding is not None:
            trajectory_embedding_expanded = trajectory_embedding.unsqueeze(1)
            fused = torch.cat([enhanced_current_node_feature, trajectory_embedding_expanded], dim=-1)
            enhanced_current_node_feature = self.trajectory_fusion(fused)

    def forward(self, ..., detected_trajectories=None, trajectory_mask=None):
        # Trajectory encoding
        if self.use_trajectory and detected_trajectories is not None:
            trajectory_embedding = self.trajectory_encoder(detected_trajectories, trajectory_mask)

        # Decode with trajectory fusion
        current_node_feature, enhanced_current_node_feature = self.decode_state(
            ..., trajectory_embedding)
```

#### QNet ìˆ˜ì •:

PolicyNetê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ìˆ˜ì •:
- Trajectory encoder ì¶”ê°€
- `decode_state()` ë©”ì„œë“œì— trajectory fusion ì¶”ê°€
- `forward()` ë©”ì„œë“œì— trajectory encoding ì¶”ê°€

**ìœ„ì¹˜**: Line 1-4 (import), 199-308 (TrajectoryEncoder), 312-427 (PolicyNet), 430-568 (QNet)

---

## ðŸŽ¯ ì£¼ìš” íŠ¹ì§•

### 1. **Temporal Transformer Architecture**
- **ì‹œê°„ ì˜ì¡´ì„± í•™ìŠµ**: Positional Encoding + Self-Attention
- **ë³‘ë ¬ ì²˜ë¦¬**: ëª¨ë“  agentì˜ trajectoryë¥¼ ë™ì‹œì— ì²˜ë¦¬
- **ìœ ì—°í•œ ì‹œí€€ìŠ¤ ê¸¸ì´**: Paddingìœ¼ë¡œ ë‹¤ì–‘í•œ ê¸¸ì´ ì§€ì›

### 2. **Multi-Agent Trajectory Aggregation**
- **Cross-Attention**: ì—¬ëŸ¬ ë¡œë´‡ì˜ trajectoryë¥¼ í†µí•©
- **Adaptive Weighting**: Attention mechanismìœ¼ë¡œ ì¤‘ìš”ë„ ìžë™ í•™ìŠµ
- **Scalable**: ê°ì§€ëœ ë¡œë´‡ ìˆ˜ì— ê´€ê³„ì—†ì´ ê³ ì •ëœ ì¶œë ¥ ì°¨ì›

### 3. **Feature Normalization**
- **ìƒëŒ€ ì¢Œí‘œ**: í˜„ìž¬ ë¡œë´‡ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
- **ë²”ìœ„ ì •ê·œí™”**: ëª¨ë“  featureë¥¼ [-1, 1] ë˜ëŠ” [0, 1] ë²”ìœ„ë¡œ ë³€í™˜
- **ì•ˆì •ì ì¸ í•™ìŠµ**: Gradient ì•ˆì •ì„± í–¥ìƒ

---

## ðŸ“Š Trajectory Feature êµ¬ì„±

ê° trajectory stepì€ 4ì°¨ì› featureë¡œ í‘œí˜„ë©ë‹ˆë‹¤:

```python
feature = [dx_norm, dy_norm, heading_norm, velocity_norm]
```

1. **dx_norm, dy_norm**: ìƒëŒ€ ì¢Œí‘œ (í˜„ìž¬ ë¡œë´‡ ê¸°ì¤€)
   - ì •ê·œí™”: `/ (UPDATING_MAP_SIZE / 2)`

2. **heading_norm**: ë°©í–¥ (0-360ë„)
   - ì •ê·œí™”: `/ 360.0` â†’ [0, 1]

3. **velocity_norm**: ì†ë„
   - ì •ê·œí™”: `/ (VELOCITY * NUM_SIM_STEPS)`

---

## ðŸš€ ì‚¬ìš© ë°©ë²•

### í•™ìŠµ ì‹œìž‘:
```bash
conda activate marvel
python driver.py
```

### Trajectory ê¸°ëŠ¥ ë„ê¸°:
```python
# utils/model.pyì—ì„œ
policy_net = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, use_trajectory=False)
q_net = QNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, TRAIN_ALGO, use_trajectory=False)
```

---

## ðŸ” ë””ë²„ê¹… ë° í…ŒìŠ¤íŠ¸

### 1. Network ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸:
```python
from parameter import *
from utils.model import PolicyNet, QNet
import torch

policy_net = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, use_trajectory=True)
q_net = QNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, TRAIN_ALGO, use_trajectory=True)
print("Networks initialized successfully!")
```

### 2. FOV ê°ì§€ í…ŒìŠ¤íŠ¸:
```python
from utils.agent import Agent

# agent.get_robots_in_fov(robot_locations) í˜¸ì¶œ
detected_ids = agent.get_robots_in_fov(robot_locations)
print(f"Detected robots: {detected_ids}")
```

### 3. Trajectory Buffer í™•ì¸:
```python
from utils.multi_agent_worker import MultiAgentWorker

# worker.trajectory_buffer ì¶œë ¥
for agent_id, trajectory in worker.trajectory_buffer.items():
    print(f"Agent {agent_id}: {len(trajectory)} steps")
```

---

## ðŸ“ êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­

### 1. **Episode Buffer**
- Trajectory ì •ë³´ëŠ” **ì‹¤ì‹œê°„ìœ¼ë¡œë§Œ** ì‚¬ìš©ë©ë‹ˆë‹¤
- Episode bufferì—ëŠ” ì €ìž¥ë˜ì§€ ì•ŠìŒ (ë§¤ë²ˆ ìƒˆë¡œ ê³„ì‚°)
- ì´ìœ : TrajectoryëŠ” í™˜ê²½ ìƒíƒœì— ì˜ì¡´í•˜ë¯€ë¡œ ì €ìž¥ ì‹œ ë©”ëª¨ë¦¬ ë¶€ë‹´ ë° ìž¬í˜„ì„± ë¬¸ì œ

### 2. **Observation êµ¬ì¡° ë³€ê²½**
- ê¸°ì¡´ 9ê°œ ìš”ì†Œ â†’ 11ê°œ ìš”ì†Œë¡œ í™•ìž¥
- ê¸°ì¡´ ì½”ë“œì—ì„œ observation unpacking ì‹œ ì£¼ì˜ í•„ìš”

### 3. **Backward Compatibility**
- `use_trajectory=False`ë¡œ ì„¤ì • ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ë™ìž‘
- ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹œ í˜¸í™˜ì„± í™•ì¸ í•„ìš”

### 4. **Performance ê³ ë ¤ì‚¬í•­**
- Trajectory EncoderëŠ” ì¶”ê°€ ì—°ì‚° ë¹„ìš© ë°œìƒ
- GPU ì‚¬ìš© ê¶Œìž¥ (`USE_GPU_GLOBAL = True`)

---

## ðŸŽ¨ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Multi-Robot Environment                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Robot 0 â”‚  â”‚ Robot 1 â”‚  â”‚ Robot 2 â”‚  â”‚ Robot 3 â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚            â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ FOV Detectionâ”‚
              â”‚ (Agent.get_  â”‚
              â”‚ robots_in_   â”‚
              â”‚ fov())       â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Trajectory Extraction   â”‚
        â”‚ (Recent N steps)        â”‚
        â”‚ - Position (x, y)       â”‚
        â”‚ - Heading (Î¸)           â”‚
        â”‚ - Velocity (v)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Feature Projection    â”‚
        â”‚   + Positional Encoding â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Temporal Transformer    â”‚
        â”‚ (Self-Attention over    â”‚
        â”‚  time steps)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Agent Aggregation      â”‚
        â”‚  (Cross-Attention)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Trajectory Embedding   â”‚
        â”‚  [batch, 64]            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   State Fusion          â”‚
        â”‚   (Concat + Linear)     â”‚
        â”‚                         â”‚
        â”‚   Current State â”€â”€â”€â”€â”   â”‚
        â”‚                     â”‚   â”‚
        â”‚   Trajectory â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â–ºâ”‚
        â”‚   Embedding            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Policy / Q-Network    â”‚
        â”‚   Action Selection      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ ìˆ˜ì • ì‚¬í•­

test_driver.pyë¥¼ í†µí•´ í•™ìŠµëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ë•Œë„ trajectory encoderê°€ ë°˜ì˜ë˜ë„ë¡ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤:

### 1. **test_parameter.py** ìˆ˜ì •

```python
# Network parameters
USE_TRAJECTORY = True  # Enable trajectory encoder

# Trajectory tracking parameters (same as parameter.py)
TRAJECTORY_HISTORY_LENGTH = 10
TRAJECTORY_FEATURE_DIM = 4
TRAJECTORY_EMBEDDING_DIM = 64
MAX_DETECTED_AGENTS = 10  # Conservative estimate for test
```

**ìœ„ì¹˜**: Line 59-66

### 2. **test_driver.py** ìˆ˜ì •

#### Runner í´ëž˜ìŠ¤ì˜ network ì´ˆê¸°í™”:
```python
# ê¸°ì¡´:
self.local_network = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN)

# ë³€ê²½ í›„:
self.local_network = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, use_trajectory=USE_TRAJECTORY)
```

**ìœ„ì¹˜**: Line 128

### 3. **utils/test_worker.py** ìˆ˜ì •

#### Import ì¶”ê°€:
```python
from collections import deque
```

#### Trajectory Buffer ì´ˆê¸°í™” (`__init__` ë©”ì„œë“œ):
```python
# Initialize trajectory buffer for each agent
self.trajectory_buffer = {}
for i in range(self.n_agents):
    self.trajectory_buffer[i] = deque(maxlen=TRAJECTORY_HISTORY_LENGTH)
    start_location = self.env.robot_locations[i]
    self.trajectory_buffer[i].append((
        start_location[0],
        start_location[1],
        self.env.angles[i],
        0.0
    ))
```

**ìœ„ì¹˜**: Line 6, 42-53

#### Observation ìƒì„± ì‹œ trajectory_buffer ì „ë‹¬:
```python
# ê¸°ì¡´:
observation = robot.get_observation(pad=False)

# ë³€ê²½ í›„:
observation = robot.get_observation(
    pad=False,
    robot_locations=self.env.robot_locations,
    trajectory_buffer=self.trajectory_buffer
)
```

**ìœ„ì¹˜**: Line 83-87

#### Trajectory ì—…ë°ì´íŠ¸:
```python
# Update trajectory buffer
prev_trajectory = self.trajectory_buffer[robot.id][-1] if len(self.trajectory_buffer[robot.id]) > 0 else None
if prev_trajectory is not None:
    prev_x, prev_y = prev_trajectory[0], prev_trajectory[1]
    velocity = np.linalg.norm(next_location - np.array([prev_x, prev_y])) / NUM_SIM_STEPS
else:
    velocity = 0.0

self.trajectory_buffer[robot.id].append((
    next_location[0],
    next_location[1],
    robot.heading,
    velocity
))
```

**ìœ„ì¹˜**: Line 159-172

#### `__main__` ë¶€ë¶„ ìˆ˜ì •:
```python
# ê¸°ì¡´:
policy_net = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN)

# ë³€ê²½ í›„:
policy_net = PolicyNet(NODE_INPUT_DIM, EMBEDDING_DIM, NUM_ANGLES_BIN, use_trajectory=USE_TRAJECTORY)
```

**ìœ„ì¹˜**: Line 377

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²•:

```bash
conda activate marvel
python test_driver.py
```

### ì£¼ì˜ì‚¬í•­:

1. **ì²´í¬í¬ì¸íŠ¸ í˜¸í™˜ì„±**:
   - Trajectory encoderê°€ í¬í•¨ëœ ëª¨ë¸ë¡œ í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤
   - ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `USE_TRAJECTORY = False`ë¡œ ì„¤ì •í•˜ì„¸ìš”

2. **ë™ì  Agent ìˆ˜**:
   - Testì—ì„œëŠ” agent ìˆ˜ê°€ ë™ì ìœ¼ë¡œ ë³€ê²½ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤
   - `MAX_DETECTED_AGENTS`ë¥¼ ì¶©ë¶„ížˆ í¬ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤ (10)

3. **ì„±ëŠ¥ ë¹„êµ**:
   - Trajectory ê¸°ëŠ¥ ON/OFFë¡œ ì„±ëŠ¥ ë¹„êµ ê°€ëŠ¥
   - `test_parameter.py`ì˜ `USE_TRAJECTORY` í”Œëž˜ê·¸ë¡œ ì œì–´

---

## ðŸŽ¨ í–¥ìƒëœ ì‹œê°í™” ê¸°ëŠ¥

test_driver.pyë¥¼ í†µí•´ ìƒì„±ë˜ëŠ” GIFì— FOV ë‚´ ê°ì§€ëœ ë¡œë´‡ì˜ trajectoryë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.

### ì‹œê°í™” íŠ¹ì§•:

#### **ì™¼ìª½ íŒ¨ë„ (Belief Map + Trajectories)**:
1. **ê¸°ë³¸ Trajectory**: ëª¨ë“  ë¡œë´‡ì˜ trajectoryë¥¼ ë°˜íˆ¬ëª…í•˜ê²Œ í‘œì‹œ (alpha=0.4)
2. **ê°ì§€ëœ Trajectory ê°•ì¡°**:
   - ë‹¤ë¥¸ ë¡œë´‡ì˜ FOVì— ê°ì§€ëœ ë¡œë´‡ì˜ trajectoryë¥¼ ë‘ê»ê³  ì ì„ ìœ¼ë¡œ í‘œì‹œ
   - í˜„ìž¬ ìœ„ì¹˜ì— í°ìƒ‰ í…Œë‘ë¦¬ì˜ ì›í˜• ë§ˆì»¤ ì¶”ê°€
   - linewidth=3.0, linestyle='--'

#### **ì˜¤ë¥¸ìª½ íŒ¨ë„ (FOV Cones + Detection Links)**:
1. **FOV Cone**: ê° ë¡œë´‡ì˜ ì‹œì•¼ ë²”ìœ„ë¥¼ ë¶€ì±„ê¼´ë¡œ í‘œì‹œ
2. **ê°ì§€ëœ Trajectory ê°•ì¡°**: ì™¼ìª½ íŒ¨ë„ê³¼ ë™ì¼
3. **Detection Links**: ê°ì§€í•˜ëŠ” ë¡œë´‡ê³¼ ê°ì§€ëœ ë¡œë´‡ ì‚¬ì´ë¥¼ í°ìƒ‰ ì ì„ ìœ¼ë¡œ ì—°ê²°
4. **Detection Summary**: ì œëª©ì— ê° ë¡œë´‡ì´ ê°ì§€í•œ ë‹¤ë¥¸ ë¡œë´‡ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ

### êµ¬í˜„ ì½”ë“œ:

```python
def get_detected_robots_in_fov(self, robot, robot_locations, robot_headings):
    """Helper function to detect which robots are in the FOV of a given robot"""
    detected_robots = []
    robot_loc = get_coords_from_cell_position(robot_locations[robot.id], self.env.belief_info)

    for other_robot in self.robot_list:
        if other_robot.id == robot.id:
            continue

        other_loc = get_coords_from_cell_position(robot_locations[other_robot.id], self.env.belief_info)

        # Calculate distance
        distance = np.linalg.norm(other_loc - robot_loc)

        # Check if within sensor range
        if distance > self.sensor_range:
            continue

        # Calculate angle to the other robot
        delta = other_loc - robot_loc
        angle_to_robot = np.degrees(np.arctan2(delta[1], delta[0])) % 360

        # Calculate angle difference considering FOV
        angle_diff = (angle_to_robot - robot_headings[robot.id] + 180) % 360 - 180

        # Check if within FOV
        if np.abs(angle_diff) <= self.fov / 2:
            detected_robots.append(other_robot.id)

    return detected_robots
```

### ì‹œê°í™” ì˜ˆì‹œ:

```
Title: Explored: 0.85  Distance: 45.2
       Headings: Red-90Â°, Blue-45Â°, Green-180Â°, Yellow-270Â°
       FOV Detections: Red detects: Blue, Green | Blue detects: Red

[Left Panel]                    [Right Panel]
- All trajectories (faded)      - All trajectories (faded)
- Detected: Blue (thick dash)   - Detected: Blue (thick dash)
- Detected: Green (thick dash)  - Detection links (white dash)
- Detected: Red (thick dash)    - FOV cones (semi-transparent)
```

### ì‹œê°ì  ìš”ì†Œ:

| ìš”ì†Œ | ìŠ¤íƒ€ì¼ | ì˜ë¯¸ |
|------|--------|------|
| ì¼ë°˜ Trajectory | ê°€ëŠ” ì‹¤ì„ , alpha=0.4 | ëª¨ë“  ë¡œë´‡ì˜ ì´ë™ ê²½ë¡œ |
| ê°ì§€ëœ Trajectory | ë‘êº¼ìš´ ì ì„ , alpha=1.0 | ë‹¤ë¥¸ ë¡œë´‡ì˜ FOVì— í¬ì°©ëœ ê²½ë¡œ |
| í˜„ìž¬ ìœ„ì¹˜ ë§ˆì»¤ | í°ìƒ‰ í…Œë‘ë¦¬ ì› | ê°ì§€ëœ ë¡œë´‡ì˜ í˜„ìž¬ ìœ„ì¹˜ |
| Detection Link | í°ìƒ‰ ì ì„  | ê°ì§€ ê´€ê³„ ì—°ê²°ì„  |
| FOV Cone | ë¶€ì±„ê¼´, alpha=0.3 | ë¡œë´‡ì˜ ì‹œì•¼ ë²”ìœ„ |

---

## ðŸ“š ì°¸ê³  ìžë£Œ

### Training ê´€ë ¨ íŒŒì¼:
- `parameter.py`: Line 80-84 (Trajectory parameters)
- `driver.py`: PolicyNet/QNet ì´ˆê¸°í™” ë¶€ë¶„
- `utils/multi_agent_worker.py`: Line 27, 64-75, 168-181, 91-94, 241-244
- `utils/agent.py`: Line 182, 245-255, 257-260, 384-486, 510-521, 544
- `utils/model.py`: Line 1-4, 199-308, 312-427, 430-568

### Testing ê´€ë ¨ íŒŒì¼:
- `test_parameter.py`: Line 59-66 (Trajectory parameters)
- `test_driver.py`: Line 40-45 (global_network), Line 128 (Runner.local_network)
- `utils/test_worker.py`: Line 6, 42-53, 83-87, 159-172, 377
  - Line 284-313: `get_detected_robots_in_fov()` - FOV ë‚´ ë¡œë´‡ ê°ì§€ í•¨ìˆ˜
  - Line 315-474: `plot_local_env_sim()` - í–¥ìƒëœ ì‹œê°í™” (ê°ì§€ëœ trajectory ê°•ì¡°)

### í•µì‹¬ í•¨ìˆ˜:
- `MultiAgentWorker.__init__()`: Trajectory buffer ì´ˆê¸°í™”
- `Agent.get_robots_in_fov()`: FOV ë‚´ ë¡œë´‡ ê°ì§€
- `Agent._get_detected_trajectories()`: Trajectory ì¶”ì¶œ ë° ì¸ì½”ë”©
- `TrajectoryEncoder.forward()`: Temporal transformer ì²˜ë¦¬
- `PolicyNet.decode_state()`: Trajectory fusion

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

êµ¬í˜„ ì™„ë£Œ í•­ëª©:
- [x] Trajectory íŒŒë¼ë¯¸í„° ì¶”ê°€ (parameter.py)
- [x] Trajectory buffer êµ¬í˜„ (multi_agent_worker.py)
- [x] FOV ê°ì§€ í•¨ìˆ˜ (agent.py)
- [x] Trajectory Encoder with Transformer (model.py)
- [x] PolicyNet í†µí•© (model.py)
- [x] QNet í†µí•© (model.py)
- [x] Observation ìƒì„± ì—…ë°ì´íŠ¸ (agent.py)
- [ ] ì‹¤ì œ í•™ìŠµ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ

---

## ðŸ’¡ í–¥í›„ ê°œì„  ë°©í–¥

1. **Trajectory ì˜ˆì¸¡**: ë¯¸ëž˜ trajectory ì˜ˆì¸¡ ê¸°ëŠ¥ ì¶”ê°€
2. **Communication**: ëª…ì‹œì  agent ê°„ communication channel
3. **Hierarchical Attention**: ì‹œê°„/ê³µê°„ ê³„ì¸µì  attention
4. **Memory Module**: Long-term trajectory memory
5. **Adaptive History Length**: ë™ì  history ê¸¸ì´ ì¡°ì •

---

**ìž‘ì„±ì¼**: 2025-11-25
**ë²„ì „**: 1.0
**ìž‘ì„±ìž**: Claude (Anthropic)
